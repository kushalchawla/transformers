python run_language_modeling.py --mlm --model_name_or_path=bert-base-uncased --train_data_file=../../../../../casino/pre-training/storage/data/dummy/train.txt --eval_data_file=../../../../../casino/pre-training/storage/data/dummy/valid.txt --do_train --do_eval --output_dir=../../../../../casino/pre-training/storage/logs/dummy1 --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --learning_rate=5e-5 --num_train_epochs=10 --save_steps=10000 --save_total_limit=20 --max_steps=100 --evaluate_during_training --evaluation_strategy=steps --logging_steps=10 --eval_steps=20 --mlm_probability=0.15

salloc --ntasks=4 --time=5:00:00 --gres=gpu:v100:1

python run_language_modeling.py --mlm --model_name_or_path=bert-base-uncased --train_data_file=../../../../../casino/pre-training/storage/data/for_pretraining/train.txt --eval_data_file=../../../../../casino/pre-training/storage/data/for_pretraining/valid.txt --do_train --do_eval --output_dir=../../../../../casino/pre-training/storage/logs/actual1 --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --learning_rate=5e-5 --num_train_epochs=20 --save_steps=2875 --save_total_limit=20 --max_steps=100 --evaluate_during_training --evaluation_strategy=steps --logging_steps=100 --eval_steps=100 --mlm_probability=0.15
